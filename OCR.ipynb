{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Xrfyjg6--Pz5",
        "colab_type": "code",
        "outputId": "e374e3f0-295f-4656-a6b3-7c3f4f8624c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install arabic_reshaper\n",
        "!pip install python-bidi\n",
        "\n",
        "# !wget 'https://www.fontyab.com/wp-content/uploads/Far_khodkar.zip'\n",
        "# !unzip 'Far_khodkar.zip'\n",
        "\n",
        "!wget 'https://www.fontyab.com/wp-content/uploads/B-Mitra.zip'\n",
        "!unzip 'B-Mitra.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting arabic_reshaper\n",
            "  Downloading https://files.pythonhosted.org/packages/50/77/696617b49322441517a725faadbf14bc00d165ba3a8211432cb287207b5f/arabic_reshaper-2.0.14-py3-none-any.whl\n",
            "Collecting configparser (from arabic_reshaper)\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/69/c2ce7e91c89dc073eb1aa74c0621c3eefbffe8216b3f9af9d3885265c01c/configparser-3.5.0.tar.gz\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from arabic_reshaper) (0.16.0)\n",
            "Building wheels for collected packages: configparser\n",
            "  Running setup.py bdist_wheel for configparser ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a3/61/79/424ef897a2f3b14684a7de5d89e8600b460b89663e6ce9d17c\n",
            "Successfully built configparser\n",
            "Installing collected packages: configparser, arabic-reshaper\n",
            "Successfully installed arabic-reshaper-2.0.14 configparser-3.5.0\n",
            "Collecting python-bidi\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/a7/ea6334b798546ed8584cb8cdc5d153c289294287b4ab46e9a4242480eae3/python_bidi-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from python-bidi) (1.11.0)\n",
            "Installing collected packages: python-bidi\n",
            "Successfully installed python-bidi-0.4.0\n",
            "--2019-01-17 18:16:54--  https://www.fontyab.com/wp-content/uploads/B-Mitra.zip\n",
            "Resolving www.fontyab.com (www.fontyab.com)... 89.42.209.236\n",
            "Connecting to www.fontyab.com (www.fontyab.com)|89.42.209.236|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53127 (52K) [application/zip]\n",
            "Saving to: ‘B-Mitra.zip’\n",
            "\n",
            "B-Mitra.zip         100%[===================>]  51.88K  88.1KB/s    in 0.6s    \n",
            "\n",
            "2019-01-17 18:16:56 (88.1 KB/s) - ‘B-Mitra.zip’ saved [53127/53127]\n",
            "\n",
            "Archive:  B-Mitra.zip\n",
            "   creating: B-Mitra/\n",
            "  inflating: B-Mitra/B Mitra Bold_0.ttf  \n",
            "  inflating: B-Mitra/B Mitra_0.ttf   \n",
            "  inflating: B-Mitra/Fontyab.com.url  \n",
            "  inflating: B-Mitra/Fontyab.ir.url  \n",
            "  inflating: B-Mitra/read me!.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HCsHlVXX9Vkl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageDraw\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ussMW4R-g6OO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# !cp X.npy 'gdrive/My Drive/OCR/X_30000.npy'\n",
        "# !cp y.npy 'gdrive/My Drive/OCR/y_30000.npy'\n",
        "\n",
        "!cp 'gdrive/My Drive/OCR/names.txt' names.txt\n",
        "!cp 'gdrive/My Drive/OCR/lastName.txt' lastName.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKpc6O8s97cZ",
        "colab_type": "code",
        "outputId": "0d228bbd-306a-438e-ca2f-97a61627ec6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "cell_type": "code",
      "source": [
        "img = Image.fromarray(np.zeros((90, 100)))\n",
        "draw = ImageDraw.Draw(img)\n",
        "font = ImageFont.truetype('B-Mitra/B Mitr-0.ttf', 60)\n",
        "text = get_display(arabic_reshaper.reshape(\"ی\"))\n",
        "draw.text((0, 10), text, 255, font=font)\n",
        "img = 255 - np.array(img)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3784d288c8f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B-Mitra/B Mitr-0.ttf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marabic_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ی\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mttf_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, font, size, index, encoding)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: cannot open resource"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "H18SNrPCDJJU",
        "colab_type": "code",
        "outputId": "2da71cb1-cd85-4e14-8581-6503dc1da674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "file = open('names.txt')\n",
        "names = file.read().split('\\n')\n",
        "file.close()\n",
        "\n",
        "file = open('lastName.txt')\n",
        "names += file.read().split('\\n')\n",
        "file.close()\n",
        "\n",
        "print(\"a total of\", len(names), 'first an last names where found ')\n",
        "\n",
        "fonts = ['Far_khodkar/Far_khodkar.ttf']\n",
        "fonts = ['B-Mitra/B Mitra_0.ttf']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a total of 6351 first an last names where found \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x_01JNNIUEk8",
        "colab_type": "code",
        "outputId": "1da3cd27-293f-408e-9f21-8750f27573b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "cell_type": "code",
      "source": [
        "alphabet = {}\n",
        "alphabet_inv = []\n",
        "i = 0\n",
        "max_len = 0\n",
        "lens = [0] * 25\n",
        "for word in names:\n",
        "  lens[len(word)] += 1\n",
        "  if (len(word) > max_len):\n",
        "    max_len = len(word)\n",
        "  for ch in word:\n",
        "    if ch not in alphabet:\n",
        "      if ch != '\\ufeff' and ch != '\\u200e' and ch != '\\u200c':\n",
        "        alphabet[ch] = i\n",
        "        alphabet_inv.append(ch)\n",
        "        i += 1\n",
        "\n",
        "alphabet['<END>'] = i\n",
        "alphabet['<PAD>'] = i + 1\n",
        "\n",
        "print(alphabet)\n",
        "print(max_len)\n",
        "plt.plot(lens)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'آ': 0, 'ئ': 1, 'ی': 2, 'ر': 3, 'ا': 4, 'ل': 5, 'ب': 6, ' ': 7, 'ح': 8, 'ت': 9, 'ن': 10, 'ه': 11, 'د': 12, 'س': 13, 'ق': 14, 'گ': 15, 'خ': 16, 'ز': 17, 'ف': 18, 'م': 19, 'ک': 20, 'و': 21, 'ش': 22, 'ج': 23, 'ژ': 24, 'پ': 25, 'چ': 26, 'ث': 27, 'ذ': 28, 'غ': 29, 'ط': 30, 'ص': 31, '،': 32, 'ض': 33, 'ع': 34, 'ظ': 35, 'ي': 36, 'ك': 37, 'ء': 38, 'ة': 39, 'ُ': 40, 'أ': 41, 'ؤ': 42, '<END>': 43, '<PAD>': 44}\n",
            "21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bFM8WN-UbPTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "id": "vsptbSjoGJGA",
        "colab_type": "code",
        "outputId": "c60b1f40-d793-4eb5-a8fe-9cdd700588cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "for i in range(500):\n",
        "  if i % 1000 == 0:\n",
        "    print(i)\n",
        "    if i % 10000 == 0 and i != 0:\n",
        "      X_ = np.array(X)\n",
        "      y_ = np.array(y)\n",
        "      np.save('X.npy', X_)\n",
        "      np.save('y.npy', y_)\n",
        "    \n",
        "  font_index = np.random.randint(0, len(fonts))\n",
        "  size = np.random.randint(40, 50)\n",
        "  text_index = np.random.randint(0, len(names))\n",
        "  while len(names[text_index]) > 6:\n",
        "    text_index = np.random.randint(0, len(names))\n",
        "  \n",
        "#   if 390 <= size * 0.5 * len(names[text_index]):\n",
        "#     pos_x = 10\n",
        "#   else:\n",
        "#     pos_x = np.random.randint(10, 400 - size * 0.5 * len(names[text_index]))\n",
        "  pos_x = 10\n",
        "  pos_y = np.random.randint(10, 90 - size * 1.1)\n",
        "  \n",
        "  img = Image.fromarray(np.zeros((90, 100)))\n",
        "  draw = ImageDraw.Draw(img)  \n",
        "  font = ImageFont.truetype(fonts[font_index], size)\n",
        "  \n",
        "  text = get_display(arabic_reshaper.reshape(names[text_index][0]))\n",
        "  \n",
        "  draw.text((pos_x, pos_y), text, 255, font=font)\n",
        "  img = np.array(img)\n",
        "  \n",
        "  lable = []\n",
        "#   for ch in names[text_index]:\n",
        "#     if ch in alphabet:\n",
        "#       lable += [alphabet[ch], alphabet[ch]]\n",
        "#   lable = [alphabet[ch] for ch in names[text_index][0] if ch in alphabet]\n",
        "  lable = [alphabet[names[text_index][0]]]\n",
        "  lable.append(alphabet['<END>'])\n",
        "  while len(lable) != 7:\n",
        "    lable.append(alphabet['<PAD>'])\n",
        "  \n",
        "  X.append(img)\n",
        "  y.append(lable)\n",
        "  \n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# np.save('X.npy', X)\n",
        "# np.save('y.npy', y)\n",
        "\n",
        "print('shape of X :', X.shape)\n",
        "print('shape of y :', y.shape)\n",
        "\n",
        "plt.imshow(X[1])\n",
        "print(y[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "shape of X : (500, 90, 100)\n",
            "shape of y : (500, 7)\n",
            "[20 43 44 44 44 44 44]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAD7CAYAAACmCxvdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NkJ9ST5hcMjj",
        "colab_type": "code",
        "outputId": "81ea39c2-4db1-45b8-b002-b6a4b4fe8d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "cell_type": "code",
      "source": [
        "X = np.load('X.npy')\n",
        "y = np.load('y.npy')\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7bff966a0f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X.npy'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QR74i-m9hjWl",
        "colab_type": "code",
        "outputId": "63b40a4a-a794-41df-aa45-6e9a59b65ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, SimpleRNN, Reshape, Dense, Flatten, TimeDistributed, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kFodvqv_m2xx",
        "colab_type": "code",
        "outputId": "54582e59-ddcb-4b25-8601-6547e976eba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "X /= 255.\n",
        "X = 1 - X\n",
        "\n",
        "X = X.transpose((0, 2, 1))\n",
        "X = X.reshape(X.shape + (1, ))\n",
        "\n",
        "y = to_categorical(y)\n",
        "\n",
        "X = X[:, ::-1, :, :]\n",
        "\n",
        "X_train = X[:int(X.shape[0] * 0.8)]\n",
        "y_train = y[:int(X.shape[0] * 0.8)]\n",
        "\n",
        "X_test = X[int(X.shape[0] * 0.8):]\n",
        "y_test = y[int(X.shape[0] * 0.8):]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(400, 100, 90, 1)\n",
            "(100, 100, 90, 1)\n",
            "(400, 7, 45)\n",
            "(100, 7, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q7o2X931J210",
        "colab_type": "code",
        "outputId": "a3832057-0d17-4c61-9c98-81b04b5c050c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X_test[:5, :, :, 0].reshape((-1, 90)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa1a0742940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAE0AAAD8CAYAAAAynylgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkPCKQMDSBCxNwNIELE3A0gQsTcDSBP4HCULbo+1jn2AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Gk9t87IVMLNk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNNmodel = Sequential()\n",
        "RNNmodel = Sequential()\n",
        "model = Sequential()\n",
        "CNNTmpModel = Sequential()\n",
        "\n",
        "model.add(Conv2D(8, (3, 3), padding='same', activation='relu', input_shape=(None, 90, 1))) # 28 * 76\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2))) # 14 * 38\n",
        "\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), padding='same', activation='relu')) # 12 * 36\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2))) # 6 * 18\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu')) # 4 * 16\n",
        "model.add(MaxPooling2D((2,2), strides=(1,2))) # 4 * 8\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # 2 * 6\n",
        "model.add(MaxPooling2D((1,3), strides=(1,3))) # 1 * 3\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # 1 * 1\n",
        "model.add(MaxPooling2D((2,3), strides=(2,3)))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model.add(SimpleRNN(64, activation='softmax', return_sequences=True))\n",
        "model.add(SimpleRNN(45, activation='softmax', return_sequences=True))\n",
        "\n",
        "\n",
        "\n",
        "CNNTmpModel.add(Conv2D(8, (3, 3), padding='same', activation='relu', input_shape=(100, 90, 1))) # 28 * 76\n",
        "CNNTmpModel.add(MaxPooling2D((2,2), strides=(2,2))) # 14 * 38\n",
        "\n",
        "\n",
        "CNNTmpModel.add(Conv2D(16, (3, 3), padding='same', activation='relu')) # 12 * 36\n",
        "CNNTmpModel.add(MaxPooling2D((2,2), strides=(2,2))) # 6 * 18\n",
        "CNNTmpModel.add(Dropout(0.2))\n",
        "\n",
        "CNNTmpModel.add(Conv2D(32, (3, 3), padding='same', activation='relu')) # 4 * 16\n",
        "CNNTmpModel.add(MaxPooling2D((2,2), strides=(1,2))) # 4 * 8\n",
        "CNNTmpModel.add(Dropout(0.4))\n",
        "\n",
        "CNNTmpModel.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # 2 * 6\n",
        "CNNTmpModel.add(MaxPooling2D((1,3), strides=(1,3))) # 1 * 3\n",
        "\n",
        "CNNTmpModel.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # 1 * 1\n",
        "CNNTmpModel.add(MaxPooling2D((2,3), strides=(2,3)))\n",
        "\n",
        "CNNTmpModel.add(MaxPooling2D((12, 1), strides=(12, 1)))\n",
        "CNNTmpModel.add(Flatten())\n",
        "CNNTmpModel.add(Dense(45, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCHPsjoFTeUp",
        "colab_type": "code",
        "outputId": "1522ec88-c888-4458-9d5a-d9cf2e39e2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1302
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "CNNTmpModel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, None, 90, 8)       80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, None, 45, 8)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, None, 45, 16)      1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, None, 22, 16)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 22, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, None, 22, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, None, 11, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 11, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, None, 11, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, None, 3, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, None, 3, 64)       36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, None, 1, 64)       0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 64)          8256      \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, None, 45)          4950      \n",
            "=================================================================\n",
            "Total params: 74,518\n",
            "Trainable params: 74,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 100, 90, 8)        80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 50, 45, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 50, 45, 16)        1168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 25, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 25, 22, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 25, 22, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 24, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 24, 11, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 24, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 24, 3, 64)         36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 12, 1, 64)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 45)                2925      \n",
            "=================================================================\n",
            "Total params: 64,237\n",
            "Trainable params: 64,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7rKQPp8kwOcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "def ctc_loss(y_true, y_pred):\n",
        "  y_true = tf.argmax(y_true, axis=2)\n",
        "  y_true = tf.cast(y_true, tf.int32)\n",
        "  \n",
        "  zero = tf.constant(0, dtype=tf.int32)\n",
        "  where = tf.not_equal(y_true, zero)\n",
        "  indices = tf.where(where)\n",
        "  values = tf.gather_nd(y_true, indices)\n",
        "  sparse = tf.SparseTensor(indices, values, (batch_size, 25))\n",
        "  \n",
        "  return tf.reduce_mean(tf.nn.ctc_loss(sparse, y_pred, tf.ones(batch_size, dtype=tf.int32) * 50, time_major=False))\n",
        "\n",
        "def ctc_lambda_func(labels, y_pred):\n",
        "#   t = K.get_value(K.ctc_decode(y_pred, input_length=np.ones(100)*12,\n",
        "#                            greedy=True)[0][0])\n",
        "\n",
        "#   t = tf.hstack((t, -tf.ones((t.shape[0], 1))))\n",
        "#   print(tf.argmin(t, axis=1))\n",
        "  \n",
        "  input_length = np.ones((batch_size, 1)) * 12\n",
        "#   input_length = tf.argmin(t, axis=1)\n",
        "  label_length = np.ones((batch_size, 1)) * 2\n",
        "  \n",
        "#   batch_real_len = 12 - tf.reduce_sum((tf.argmax(y_pred, )), axis=1)\n",
        "  \n",
        "  l = tf.argmax(labels, axis=2)\n",
        "  # the 2 is critical here since the first couple outputs of the RNN\n",
        "  # tend to be garbage:\n",
        "  p = K.ctc_batch_cost(l, y_pred, input_length, label_length)\n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3LHTaCQuQpK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=1), loss=ctc_lambda_func)\n",
        "CNNTmpModel.compile(optimizer=Adam(lr=1), loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z0YzBnmAzfu8",
        "colab_type": "code",
        "outputId": "693c05ec-0aca-40b9-a274-6f85af9e3fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3525
        }
      },
      "cell_type": "code",
      "source": [
        "# CNNTmpModel.optimizer = Adam(lr=0.01)\n",
        "# CNNTmpModel.fit(X_train, y_train[:, 0, :], batch_size=batch_size, epochs=200, validation_data=(X_test, y_test[:, 0, :]))\n",
        "\n",
        "\n",
        "# for layer in model.layers[:11]:\n",
        "#   layer.trainable = False\n",
        "\n",
        "# model.optimizer = Adam(lr=0.1)\n",
        "# for i in range(100):\n",
        "  \n",
        "w1 = CNNTmpModel.get_weights()\n",
        "w2 = model.get_weights()\n",
        "\n",
        "w2[:10] = w1[:10]\n",
        "model.set_weights(w2)\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 400 samples, validate on 100 samples\n",
            "Epoch 1/100\n",
            "400/400 [==============================] - 2s 4ms/step - loss: 19.0528 - val_loss: 17.1849\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 17.2398 - val_loss: 17.6654\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 17.2051 - val_loss: 17.1755\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 17.0672 - val_loss: 17.2807\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 17.0522 - val_loss: 17.1200\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 17.0055 - val_loss: 17.0319\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9948 - val_loss: 17.1364\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9715 - val_loss: 17.0363\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9703 - val_loss: 17.0222\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9529 - val_loss: 17.0817\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9385 - val_loss: 17.0462\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9457 - val_loss: 17.0131\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9553 - val_loss: 17.0796\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 16.9529 - val_loss: 17.0086\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9532 - val_loss: 17.0693\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9595 - val_loss: 17.1071\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9384 - val_loss: 16.9940\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9310 - val_loss: 16.9978\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9674 - val_loss: 17.0955\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9421 - val_loss: 17.0244\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9426 - val_loss: 16.9772\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9153 - val_loss: 17.0830\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9345 - val_loss: 17.0110\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9437 - val_loss: 17.0363\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9524 - val_loss: 17.0345\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9700 - val_loss: 17.0421\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9442 - val_loss: 17.0791\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9403 - val_loss: 17.0305\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9367 - val_loss: 17.1243\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9506 - val_loss: 17.1022\n",
            "Epoch 31/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 16.9667 - val_loss: 16.8940\n",
            "Epoch 32/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 15.0863 - val_loss: 12.4594\n",
            "Epoch 33/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 11.7691 - val_loss: 13.3101\n",
            "Epoch 34/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 13.0943 - val_loss: 11.3658\n",
            "Epoch 35/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 10.4078 - val_loss: 7.7796\n",
            "Epoch 36/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 9.0704 - val_loss: 8.1226\n",
            "Epoch 37/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 9.5792 - val_loss: 8.0817\n",
            "Epoch 38/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 9.5543 - val_loss: 7.9756\n",
            "Epoch 39/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 9.3100 - val_loss: 7.6802\n",
            "Epoch 40/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 9.1433 - val_loss: 7.7775\n",
            "Epoch 41/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9764 - val_loss: 7.7434\n",
            "Epoch 42/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9954 - val_loss: 7.5670\n",
            "Epoch 43/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9196 - val_loss: 7.5827\n",
            "Epoch 44/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9360 - val_loss: 7.6166\n",
            "Epoch 45/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8953 - val_loss: 7.5604\n",
            "Epoch 46/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 8.8896 - val_loss: 7.6512\n",
            "Epoch 47/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8884 - val_loss: 7.5738\n",
            "Epoch 48/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8926 - val_loss: 7.5806\n",
            "Epoch 49/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8953 - val_loss: 7.6487\n",
            "Epoch 50/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8913 - val_loss: 7.5303\n",
            "Epoch 51/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9111 - val_loss: 7.6038\n",
            "Epoch 52/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8694 - val_loss: 7.6294\n",
            "Epoch 53/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8785 - val_loss: 7.5529\n",
            "Epoch 54/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8871 - val_loss: 7.5395\n",
            "Epoch 55/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8905 - val_loss: 7.5768\n",
            "Epoch 56/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8564 - val_loss: 7.5709\n",
            "Epoch 57/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8862 - val_loss: 7.5384\n",
            "Epoch 58/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8639 - val_loss: 7.5816\n",
            "Epoch 59/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8932 - val_loss: 7.5400\n",
            "Epoch 60/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8635 - val_loss: 7.5909\n",
            "Epoch 61/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8622 - val_loss: 7.5424\n",
            "Epoch 62/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8684 - val_loss: 7.5396\n",
            "Epoch 63/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8717 - val_loss: 7.5714\n",
            "Epoch 64/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8718 - val_loss: 7.5448\n",
            "Epoch 65/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8601 - val_loss: 7.5393\n",
            "Epoch 66/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8597 - val_loss: 7.5782\n",
            "Epoch 67/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8771 - val_loss: 7.5289\n",
            "Epoch 68/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8793 - val_loss: 7.5956\n",
            "Epoch 69/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8733 - val_loss: 7.5325\n",
            "Epoch 70/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8708 - val_loss: 7.5761\n",
            "Epoch 71/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8867 - val_loss: 7.5688\n",
            "Epoch 72/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8751 - val_loss: 7.5443\n",
            "Epoch 73/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8868 - val_loss: 7.5707\n",
            "Epoch 74/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8734 - val_loss: 7.5792\n",
            "Epoch 75/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8973 - val_loss: 7.5377\n",
            "Epoch 76/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8728 - val_loss: 7.5902\n",
            "Epoch 77/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8746 - val_loss: 7.5400\n",
            "Epoch 78/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8949 - val_loss: 7.6094\n",
            "Epoch 79/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8686 - val_loss: 7.5909\n",
            "Epoch 80/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9100 - val_loss: 7.5262\n",
            "Epoch 81/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8521 - val_loss: 7.5456\n",
            "Epoch 82/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8934 - val_loss: 7.6078\n",
            "Epoch 83/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8955 - val_loss: 7.5973\n",
            "Epoch 84/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8764 - val_loss: 7.4988\n",
            "Epoch 85/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9086 - val_loss: 7.5597\n",
            "Epoch 86/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9217 - val_loss: 7.6111\n",
            "Epoch 87/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9019 - val_loss: 7.5944\n",
            "Epoch 88/100\n",
            "400/400 [==============================] - 1s 1ms/step - loss: 8.8958 - val_loss: 7.6037\n",
            "Epoch 89/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9109 - val_loss: 7.5372\n",
            "Epoch 90/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9202 - val_loss: 7.6463\n",
            "Epoch 91/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9281 - val_loss: 7.6436\n",
            "Epoch 92/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9036 - val_loss: 7.5462\n",
            "Epoch 93/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8774 - val_loss: 7.6293\n",
            "Epoch 94/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8928 - val_loss: 7.5480\n",
            "Epoch 95/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.9040 - val_loss: 7.5937\n",
            "Epoch 96/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8961 - val_loss: 7.5786\n",
            "Epoch 97/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8688 - val_loss: 7.5571\n",
            "Epoch 98/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8839 - val_loss: 7.5731\n",
            "Epoch 99/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8826 - val_loss: 7.5488\n",
            "Epoch 100/100\n",
            "400/400 [==============================] - 0s 1ms/step - loss: 8.8825 - val_loss: 7.5859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1986837b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "OYG8lyugp-wq",
        "colab_type": "code",
        "outputId": "4dbba585-5ec8-4159-9c94-88ece747b0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(be)):\n",
        "  print(np.sum((be[i] - af[i]) ** 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.80629146\n",
            "0.11882983\n",
            "7.811528\n",
            "0.07857303\n",
            "12.360407\n",
            "0.1631856\n",
            "92.01965\n",
            "0.30326968\n",
            "314.79446\n",
            "0.3994335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vTPntRSA3_kC",
        "colab_type": "code",
        "outputId": "2a1c2e69-930a-441a-ef89-fb04738b862e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "cell_type": "code",
      "source": [
        "t = y_train.argmax(axis=2)[:, 0]\n",
        "plt.hist(t, bins=45)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([33.,  0.,  7., 18.,  0., 24.,  6., 38.,  0.,  0.,  9., 14.,  0.,\n",
              "        16., 20., 10.,  0., 25.,  5.,  9.,  0., 12.,  4., 21.,  0., 32.,\n",
              "        18., 19.,  0., 19.,  2.,  3.,  0., 18.,  3.,  0.,  0.,  1.,  0.,\n",
              "         2.,  0.,  2.,  0.,  1.,  9.]),\n",
              " array([ 0.        ,  0.75555556,  1.51111111,  2.26666667,  3.02222222,\n",
              "         3.77777778,  4.53333333,  5.28888889,  6.04444444,  6.8       ,\n",
              "         7.55555556,  8.31111111,  9.06666667,  9.82222222, 10.57777778,\n",
              "        11.33333333, 12.08888889, 12.84444444, 13.6       , 14.35555556,\n",
              "        15.11111111, 15.86666667, 16.62222222, 17.37777778, 18.13333333,\n",
              "        18.88888889, 19.64444444, 20.4       , 21.15555556, 21.91111111,\n",
              "        22.66666667, 23.42222222, 24.17777778, 24.93333333, 25.68888889,\n",
              "        26.44444444, 27.2       , 27.95555556, 28.71111111, 29.46666667,\n",
              "        30.22222222, 30.97777778, 31.73333333, 32.48888889, 33.24444444,\n",
              "        34.        ]),\n",
              " <a list of 45 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAD4CAYAAAAjKGdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngSxvSSqQ5S1JBbK8JalA/weMafwTt9yNdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2494b8cd68>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EWvhlhFze82F",
        "colab_type": "code",
        "outputId": "d72d0f1a-451d-450f-c52f-69f740520cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test[:1])\n",
        "\n",
        "pred[1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-228-bbe735721b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BjDTmWKDHQDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def toText(X_row, alphabet_inv):\n",
        "  X_chars = X_row.argmax(axis=1)\n",
        "  text = ''\n",
        "  for ch in X_chars:\n",
        "    if ch < len(alphabet_inv):\n",
        "      text += alphabet_inv[ch]\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KstQMgNGBnbK",
        "colab_type": "code",
        "outputId": "30ddc143-6f7e-40c2-a069-fe247abb02e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test[:10])\n",
        "for i in range(10):\n",
        "    print(i, toText(pred[i], alphabet_inv))\n",
        "  \n",
        "t = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        "\n",
        "t = np.hstack((t, -np.ones((t.shape[0], 1))))\n",
        "print(t.argmin(axis=1))\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 ب\n",
            "1 ب\n",
            "2 ب\n",
            "3 ب\n",
            "4 ب\n",
            "5 ب\n",
            "6 ب\n",
            "7 ب\n",
            "8 ب\n",
            "9 ب\n",
            "[2 2 2 2 2 2 2 2 2 2]\n",
            "[[ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]\n",
            " [ 6. 43. -1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "paSrcV_HDWf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = CNNmodel.predict(X_test[1:2])[0]\n",
        "\n",
        "print(pred.shape)\n",
        "\n",
        "plt.imshow(pred[:, 0, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-MtOL0PyaVE",
        "colab_type": "code",
        "outputId": "b92a59e2-8bb9-4258-86d3-523716b56fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_test[1])\n",
        "pred = model_tmp.predict(X_test[1:2])[0]\n",
        "\n",
        "print(pred.shape)\n",
        "\n",
        "img = 255 - pred.reshape((24, 3*64)) / pred.max() * 256\n",
        "img = cv2.resize(img, None, fx=4, fy=4, interpolation=cv2.INTER_NEAREST)\n",
        "cv2.imwrite('image_10_C.jpg', img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "(24, 3, 64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "gT0wB6TOcL6_",
        "colab_type": "code",
        "outputId": "480b7599-1171-4eb8-8193-fc1400e59c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "pred = model_tmp.predict(X_train[:100])\n",
        "print(pred.shape)\n",
        "\n",
        "pred2 = model_tmp2.predict(pred)\n",
        "\n",
        "prd = []\n",
        "for i in range(1, 13):\n",
        "  p = model_tmp2.predict(pred[:, :i])\n",
        "  prd.append(p[:, -1, :])\n",
        "\n",
        "prd = np.array(prd)\n",
        "prd = np.transpose(prd, (1, 0, 2))\n",
        "print(np.sum((prd - pred2) ** 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 12, 64)\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2ceuby5bVLR7",
        "colab_type": "code",
        "outputId": "c5589f27-4789-4e64-823d-12da5c8cd311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "model_tmp = Sequential()\n",
        "model_tmp2 = Sequential()\n",
        "\n",
        "model_tmp.add(Conv2D(8, (3, 3), padding='same', activation='relu', input_shape=(None, 90, 1))) # 28 * 76\n",
        "model_tmp.add(MaxPooling2D((2,2), strides=(2,2))) # 14 * 38\n",
        "\n",
        "\n",
        "model_tmp.add(Conv2D(16, (3, 3), padding='same', activation='relu')) # 12 * 36\n",
        "model_tmp.add(MaxPooling2D((2,2), strides=(2,2))) # 6 * 18\n",
        "model_tmp.add(Dropout(0.2))\n",
        "\n",
        "model_tmp.add(Conv2D(32, (3, 3), padding='same', activation='relu')) # 4 * 16\n",
        "model_tmp.add(MaxPooling2D((2,2), strides=(1,2))) # 4 * 8\n",
        "model_tmp.add(Dropout(0.4))\n",
        "\n",
        "model_tmp.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # 2 * 6\n",
        "model_tmp.add(MaxPooling2D((1,3), strides=(1,3))) # 1 * 3\n",
        "\n",
        "model_tmp.add(Conv2D(64, (3, 3), padding='same', activation='relu')) # 1 * 1\n",
        "model_tmp.add(MaxPooling2D((2,3), strides=(2,3)))\n",
        "\n",
        "model_tmp.add(TimeDistributed(Flatten()))\n",
        "\n",
        "model_tmp.add(SimpleRNN(64, activation='softmax', return_sequences=True))\n",
        "model_tmp2.add(SimpleRNN(45, activation='softmax', return_sequences=True, input_dim=64))\n",
        "\n",
        "# model_tmp.add(MaxPooling2D((12, 1), strides=(12, 1)))\n",
        "# model_tmp.add(Flatten())\n",
        "# model_tmp.add(Dense(64, activation='relu'))\n",
        "# model_tmp.add(Dense(45, activation='softmax'))\n",
        "\n",
        "print(len(model.get_weights()))\n",
        "for i in range(len(model.get_weights())):\n",
        "  print('\\t', i, model.get_weights()[i].shape)\n",
        "model_tmp.set_weights(model.get_weights()[:13])\n",
        "model_tmp2.set_weights(model.get_weights()[13:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `SimpleRNN` call to the Keras 2 API: `SimpleRNN(45, activation=\"softmax\", return_sequences=True, input_shape=(None, 64))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "\t 0 (3, 3, 1, 8)\n",
            "\t 1 (8,)\n",
            "\t 2 (3, 3, 8, 16)\n",
            "\t 3 (16,)\n",
            "\t 4 (3, 3, 16, 32)\n",
            "\t 5 (32,)\n",
            "\t 6 (3, 3, 32, 64)\n",
            "\t 7 (64,)\n",
            "\t 8 (3, 3, 64, 64)\n",
            "\t 9 (64,)\n",
            "\t 10 (64, 64)\n",
            "\t 11 (64, 64)\n",
            "\t 12 (64,)\n",
            "\t 13 (64, 45)\n",
            "\t 14 (45, 45)\n",
            "\t 15 (45,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v5U9j2f9T-Ui",
        "colab_type": "code",
        "outputId": "24472c0d-eb9d-4160-d12d-c3d62767b5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "cell_type": "code",
      "source": [
        "t = y_train[:100].argmax(axis=2)\n",
        "\n",
        "pad = np.array([[44] * 2 for i in range(100)])\n",
        "\n",
        "\n",
        "y_pred = np.hstack((pad, pad, t[:, :1], pad, t[:, 1:2], pad, pad))\n",
        "y_pred = to_categorical(y_pred)\n",
        "\n",
        "pred = model.predict(X_train[:100])\n",
        "\n",
        "print(y_pred.shape)\n",
        "print(pred.shape)\n",
        "print(y_train[:100].shape)\n",
        "\n",
        "with tf.Session():\n",
        "  print(ctc_lambda_func(y_train[:100], y_pred).eval())\n",
        "  t = ctc_lambda_func(y_train[:100], y_pred)\n",
        "  print(K.gradients(t, y_pred[0]))\n",
        "  print(ctc_lambda_func(y_train[:100], pred).eval())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b1a05152f564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    }
  ]
}